package org.pandalanguage.plex

uses org.pandalanguage.plex.AcceptState
uses org.pandalanguage.plex.NFA
uses org.pandalanguage.plex.runtime.DFA

====================================================================================================
A simple lexical analyzer generator for Panda, used to build pandac's lexer.
====================================================================================================
class PLex {
    def tokens := HashMap<String, Regex>()
    def out:IndentedOutputStream

    method process(cfg:File, out:OutputStream) {
        self.out := IndentedOutputStream(out)
        load(cfg)
        tokens.clear()
    }

    function escape(s:String):String {
        def result := MutableString()
        for i in 0 .. s.length {
            if "+*?|.()[]".contains(s[i]) {
                result.append("\\")
            }
            result.append(s[i])
        }
        return result.convert()
    }

    method load(input:File) {
        def nfa := NFA()
        out.printLine("package org.pandalanguage.pandac.parser")
        out.printLine("uses org.pandalanguage.plex.runtime.*")
        out.printLine()
        out.printLine("choice TokenType {")
        out.level += 1
        var offset := 0
        out.printLine("EOF, -- 0")
        offset += 1
        out.write("SHIFTRIGHT")
        offset += 1
        for line in input.lines {
            line := line.trimmed()
            if line.contains(":=") {
                def id := line[0 .. line.indexOf(":=")].trimmed()
                def pattern := line[line.indexOf(":=") + 2].trimmed()
                def regex:Regex
                if pattern.startsWith('"') {
                    regex := Regex(escape(pattern[1 .. pattern.length - 1]))
                }
                else {
                    assert pattern.startsWith("/") & pattern.endsWith("/")
                    regex := Regex(pattern[1 .. pattern.length - 1])
                }
                out.printLine(", -- \{tokens.length + 1}")
                out.write(parsed[0])
                def states := regex.addToNFA(nfa, nfa.addState(AcceptState(tokens.length +
                        offset)))
                for j in 0 ... states.length - 1 {
                    nfa.addStartState(states[j])
                }
                tokens[parsed[0]] := regex
            }
            else {
                assert line.length = 0, "error parsing '\{line}'"
            }
            line := input.readLine()
        }
        out.printLine()
        out.level -= 1
        out.printLine("}")

        out.printLine()
        writeToken(out)
        out.printLine()

        def dfa := NFAtoDFA(nfa).createDFA()
        writeLexer(dfa, out)
    }

    method writeToken(out:IndentedOutputStream) {
        out.printLine("class Token : Immutable {")
        out.level += 1
        out.printLine("def type:TokenType")
        out.printLine("def text:String")
        out.printLine("def position:Position")
        out.printLine()
        out.printLine("constructor(type:TokenType, text:String, position:Position) {")
        out.level += 1
        out.printLine("self.type := type")
        out.printLine("self.text := text")
        out.printLine("self.position := position")
        out.level -= 1
        out.printLine("}")
        out.printLine()
        out.printLine("@override")
        out.printLine("function format(fmt:String):String {")
        out.level += 1
        out.printLine('return text')
        out.level -= 1
        out.printLine("}")
        out.level -= 1
        out.printLine("}")
    }

    method writeLexer(dfa:DFA, out:IndentedOutputStream) {
        out.printLine("class Lexer {")
        out.level += 1
        out.printLine("var file := 'undefined'")
        writeStateTable(dfa, out)
        out.printLine("var dfa := DFA(transitions, accepts)")
        out.printLine("function source():LineNumberInputStream {")
        out.level += 1
        out.printLine("return dfa.source")
        out.level -= 1
        out.printLine("}")
        out.printLine()
        out.printLine("@self")
        out.printLine("method source:=(source:InputStream) {")
        out.level += 1
        out.printLine("dfa.source := source")
        out.level -= 1
        out.printLine("}")
        out.printLine()
        out.printLine("method next():Token {")
        out.level += 1
        out.printLine("def raw := dfa.next()")
        out.printLine("return Token(raw.type->>(TokenType), raw.text, Position(file, " +
                "raw.startLine, raw.startColumn))")
        out.level -= 1
        out.printLine("}")
        out.level -= 1
        out.printLine("}")
    }

    method writeStateTable(dfa:DFA, out:IndentedOutputStream) {
        out.printLine("constant transitions := [")
        out.level += 1
        var separator := ""
        for a in dfa.transitions {
            out.write(separator)
            out.write("[")
            var innerSeparator := ""
            for t in a {
                out.write(separator)
                innerSeparator := ", "
                out.write(t)
            }
            out.printLine("]")
            separator := ",\n"
        }
        out.level -= 1
        out.printLine("]")
        out.printLine("constant accepts := [")
        separator := ""
        for a in dfa.accepts {
            out.write(separator)
            separator := ", "
            out.write(a)
        }
        out.printLine("]")
    }

    @class
    method main() {
        def src := "/tmp/src"
        def dst := "/tmp/dst"
        PLex().process(File(src).openInputStream(), File(dst).openOutputStream())
    }
}