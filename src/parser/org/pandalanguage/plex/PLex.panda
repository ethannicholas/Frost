package org.pandalanguage.plex

uses org.pandalanguage.plex.runtime.DFA

====================================================================================================
A simple lexical analyzer generator for Panda, used to build pandac's lexer.
====================================================================================================
class PLex {
    def tokens := HashMap<String, Regex>()

    @class
    function lastIndexOf(this:String, s:String):String.Index? {
        def startPos := this._length - s._length
        outer: for i in startPos ... 0 by -1 {
            for j in 0 .. s._length {
                if this.data[i + j] != s.data[j] {
                    continue outer
                }
            }
            return String.Index(i)
        }
        assert !this.contains(s), "returning null for \{this:panda}.lastIndex(\{s:panda})"
        return null
    }

    method printWarning(out:OutputStream) {
        out.printLine("-------- UPDATED --------")
        out.printLine("-***********************************************************************-")
        out.printLine("-********************* GENERATED CODE, DO NOT EDIT *********************-")
        out.printLine("-***********************************************************************-")
    }

    method process(inputPath:File, tokenName:String, tokenPath:File, lexerName:String,
            lexerPath:File, positionName:String) {
        def input := inputPath.openInputStream()
        def token := IndentedOutputStream(tokenPath.openOutputStream())
        def nfa := NFA()
        printWarning(token)
        token.printLine("package \{tokenName[..lastIndexOf(tokenName, ".")]}")
        token.printLine()
        token.printLine("uses \{positionName}")
        token.printLine()
        token.printLine("@final")
        def index := tokenName.next(lastIndexOf(tokenName, "."))
        token.printLine("class \{tokenName[index..]} : Value {")
        token.level += 1
        token.printLine("choice Kind {")
        token.level += 1
        -- define synthetic tokens not present in .plex file
        var offset := 0
        token.printLine("EOF")
        offset += 1
        token.printLine("SHIFTRIGHT")
        offset += 1
        token.printLine("REGEX")
        offset += 1
        for rawLine in input.lines() {
            def line := rawLine.trimmed
            if line.contains(":=") {
                def id := line[line.start .. line.indexOf(":=")].trimmed
                def pattern := line[line.offset(line.indexOf(":="), 2) .. line.end].trimmed
                def regex:Regex
                if pattern.startsWith('"') {
                    regex := Regex(escape(pattern[pattern.next(pattern.start) ..
                            pattern.previous(pattern.end)]))
                }
                else {
                    assert pattern.startsWith("/") & pattern.endsWith("/")
                    regex := Regex(pattern[pattern.next(pattern.start) ..
                            pattern.previous(pattern.end)])
                }
                token.printLine(id)
                def states := regex.addToNFA(nfa, nfa.addState(AcceptState(tokens.count +
                        offset)))
                for s in states {
                    nfa.addStartState(s)
                }
                tokens[id] := regex
            }
            else {
                assert line.byteLength = 0, "error parsing '\{line}'"
            }
        }
        token.printLine()
        token.printLine("@override")
        token.printLine("function convert():String {") -- FIXME this should be automatic in choice
        token.level += 1
        token.printLine("match self {")
        token.level += 1
        for id in tokens.keys {
            token.printLine("when \{id} { return \{id.format("panda")} }")
        }
        token.printLine("when EOF { return \"EOF\" }")
        token.printLine("when SHIFTRIGHT { return \">>\" }")
        token.printLine("when REGEX { return \"REGEX\" }")
        token.level -= 1
        token.printLine("}")
        token.level -= 1
        token.printLine("}")
        token.level -= 1
        token.printLine("}")
        token.printLine()
        token.printLine("def kind:Kind")
        token.printLine("def start:String.Index")
        token.printLine("def end:String.Index")
        token.printLine("def position:Position")
        token.printLine()
        token.printLine("init(kind:Kind, start:String.Index, end:String.Index, " +
                "position:Position) {")
        token.level += 1
        token.printLine("self.kind := kind")
        token.printLine("self.start := start")
        token.printLine("self.end := end")
        token.printLine("self.position := position")
        token.level -= 1
        token.printLine("}")
        token.level -= 1
        token.printLine("}")

        def dfa := NFAtoDFA(nfa).createDFA()
        def lexer := IndentedOutputStream(lexerPath.openOutputStream())
        writeLexer(tokenName, lexerName, lexerPath, positionName, dfa, lexer)
        tokens.clear()
        for i in 0 ... DFA.END_CHAR.convert()->Int {
            dfa.transitions[i].destroy()
        }
        dfa.transitions.destroy()
        dfa.accepts.destroy()
    }

    function escape(s:String):String {
        def result := MutableString()
        for c in s.utf8 {
            if "+*?|.()[]".contains(c) {
                result.append("\\")
            }
            result.append(c)
        }
        return result.finish()
    }

    method writeLexer(tokenName:String, lexerName:String, lexerPath:File, positionName:String,
            dfa:DFA, out:IndentedOutputStream) {
        printWarning(out)
        out.printLine("package \{lexerName[..lastIndexOf(lexerName, ".")]}")
        out.printLine()
        out.printLine("uses panda.unsafe.Pointer")
        out.printLine("uses org.pandalanguage.plex.runtime.DFA")
        out.printLine("uses \{positionName}")
        out.printLine()
        out.printLine("@final")
        out.printLine("class \{lexerName[lexerName.next(lastIndexOf(lexerName, "."))..]} {")
        out.level += 1
        out.printLine("def dfa:DFA")
        out.printLine()
        out.printLine("def transitions := getTransitions()")
        out.printLine()
        out.printLine("def accepts := getAccepts()")
        out.printLine()
        out.printLine("method start(source:String) {")
        out.printLine("    dfa := DFA(source, \{dfa.stateCount}, transitions, accepts)")
        out.printLine("}")
        out.printLine()
        writeStateTable(dfa, out)
        out.printLine()
        out.printLine("method next():\{tokenName} {")
        out.level += 1
        out.printLine("def raw := dfa.next()")
        out.printLine("return \{tokenName}(\{tokenName}.Kind(raw.kind), raw.start, raw.end, " +
                "Position(raw.line, raw.column))")
        out.level -= 1
        out.printLine("}")
        out.level -= 1
        out.printLine("}")
    }

    method writeStateTable(dfa:DFA, out:IndentedOutputStream) {
        out.printLine("@class")
        out.printLine("function alloc(count:Int, fill:Int):Pointer<Int> {")
        out.printLine("    def result := Pointer<Int>.alloc(count)")
        out.printLine("    for i in 0 .. count {")
        out.printLine("        result[i] := fill")
        out.printLine("    }")
        out.printLine("    return result")
        out.printLine("}")
        out.printLine()
        out.printLine("@class")
        out.printLine("function getTransitions():Pointer<Pointer<Int>> {")
        out.level += 1
        out.printLine("def result := Pointer<Pointer<Int>>.alloc(\{DFA.END_CHAR} + 1)")
        def destroys := MutableString()
        outer: for i in 0 ... DFA.END_CHAR.convert()->Int {
            for j in 0 .. i {
                var equal := true
                for k in 0 .. dfa.stateCount {
                    if dfa.transitions[i][k] != dfa.transitions[j][k] {
                        equal := false
                        break
                    }
                }
                if equal {
                    out.printLine("result[\{i}] := result[\{j}]")
                    continue outer
                }
            }
            destroys.append("transitions[\{i}].destroy()\n")
            def a := dfa.transitions[i]
            def counts := Array<Int>(dfa.stateCount)
            for j in 0 .. dfa.stateCount {
                counts.add(0)
            }
            var maxIndex := 0
            for j in 0 .. dfa.stateCount {
                counts[a[j]] += 1
                if counts[a[j]] > counts[maxIndex] {
                    maxIndex := a[j]
                }
            }
            def fill := maxIndex
            out.printLine("result[\{i}] := alloc(\{dfa.stateCount}, \{fill})")
            for j in 0 .. dfa.stateCount {
                if a[j] != fill {
                    out.printLine("result[\{i}][\{j}] := \{a[j]}")
                }
            }
        }
        out.printLine("return result")
        out.level -= 1
        out.printLine("}")
        out.printLine()
        out.printLine("@class")
        out.printLine("function getAccepts():Pointer<Int> {")
        out.level += 1
        out.printLine("def result := Pointer<Int>.alloc(\{dfa.stateCount})")
        for i in 0 .. dfa.stateCount {
            out.printLine("result[\{i}] := \{dfa.accepts[i]}")
        }
        out.printLine("return result")
        out.level -= 1
        out.printLine("}")
        out.printLine()
        out.printLine("@override")
        out.printLine("method cleanup() {")
        out.level += 1
        out.print(destroys)
        out.printLine("transitions.destroy()")
        out.printLine("accepts.destroy()")
        out.level -= 1
        out.printLine("}")
    }

    @class
    method main(args:ListView<String>) {
        assert args.count = 7
        def input := File(args[1])
        def tokenName := args[2]
        def tokenPath := File(args[3])
        def lexerName := args[4]
        def lexerPath := File(args[5])
        def positionName := args[6]
        def dst := File("org/pandalanguage/pandac/parser")
        dst.createDirectories()
        PLex().process(input, tokenName, tokenPath, lexerName, lexerPath, positionName)
    }
}